{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, RNN, InputLayer, Dropout\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_Text=open('wonderland.txt').read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144520"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars=sorted(list(set(raw_Text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_int=dict((c,i) for i,c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_chars=len(raw_Text)\n",
    "n_vocab=len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144520"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len=100\n",
    "dataX=[]\n",
    "dataY=[]\n",
    "for i in range(0,n_chars-seq_len):\n",
    "    seq_in=raw_Text[i:i+seq_len]\n",
    "    seq_out=raw_Text[i+seq_len]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_patterns=len(dataX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144420"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.reshape(dataX,(n_patterns, seq_len, 1))\n",
    "X=X/float(n_vocab)\n",
    "y=np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(LSTM(256,input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the checkpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "144420/144420 [==============================] - 820s 6ms/step - loss: 2.8452\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.84524, saving model to weights-improvement-01-2.8452.hdf5\n",
      "Epoch 2/20\n",
      "144420/144420 [==============================] - 837s 6ms/step - loss: 2.6123\n",
      "\n",
      "Epoch 00002: loss improved from 2.84524 to 2.61230, saving model to weights-improvement-02-2.6123.hdf5\n",
      "Epoch 3/20\n",
      "144420/144420 [==============================] - 754s 5ms/step - loss: 2.4838\n",
      "\n",
      "Epoch 00003: loss improved from 2.61230 to 2.48376, saving model to weights-improvement-03-2.4838.hdf5\n",
      "Epoch 4/20\n",
      "144420/144420 [==============================] - 851s 6ms/step - loss: 2.3810\n",
      "\n",
      "Epoch 00004: loss improved from 2.48376 to 2.38097, saving model to weights-improvement-04-2.3810.hdf5\n",
      "Epoch 5/20\n",
      "144420/144420 [==============================] - 731s 5ms/step - loss: 2.2908\n",
      "\n",
      "Epoch 00005: loss improved from 2.38097 to 2.29082, saving model to weights-improvement-05-2.2908.hdf5\n",
      "Epoch 6/20\n",
      "144420/144420 [==============================] - 715s 5ms/step - loss: 2.2085\n",
      "\n",
      "Epoch 00006: loss improved from 2.29082 to 2.20848, saving model to weights-improvement-06-2.2085.hdf5\n",
      "Epoch 7/20\n",
      "144420/144420 [==============================] - 714s 5ms/step - loss: 2.1350\n",
      "\n",
      "Epoch 00007: loss improved from 2.20848 to 2.13495, saving model to weights-improvement-07-2.1350.hdf5\n",
      "Epoch 8/20\n",
      "144420/144420 [==============================] - 715s 5ms/step - loss: 2.0677\n",
      "\n",
      "Epoch 00008: loss improved from 2.13495 to 2.06770, saving model to weights-improvement-08-2.0677.hdf5\n",
      "Epoch 9/20\n",
      "144420/144420 [==============================] - 719s 5ms/step - loss: 2.0056\n",
      "\n",
      "Epoch 00009: loss improved from 2.06770 to 2.00563, saving model to weights-improvement-09-2.0056.hdf5\n",
      "Epoch 10/20\n",
      "144420/144420 [==============================] - 714s 5ms/step - loss: 1.9490\n",
      "\n",
      "Epoch 00010: loss improved from 2.00563 to 1.94896, saving model to weights-improvement-10-1.9490.hdf5\n",
      "Epoch 11/20\n",
      "144420/144420 [==============================] - 897s 6ms/step - loss: 1.8947\n",
      "\n",
      "Epoch 00011: loss improved from 1.94896 to 1.89466, saving model to weights-improvement-11-1.8947.hdf5\n",
      "Epoch 12/20\n",
      " 30450/144420 [=====>........................] - ETA: 39:06 - loss: 1.8244"
     ]
    }
   ],
   "source": [
    "model.fit(X,y,epochs=20,batch_size=42, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['weights-improvement-16-1.6494.hdf5',\n",
       " 'weights-improvement-01-2.8452.hdf5',\n",
       " 'weights-improvement-10-1.9490.hdf5',\n",
       " 'wonderland.txt',\n",
       " 'weights-improvement-08-2.0677.hdf5',\n",
       " 'weights-improvement-05-2.2908.hdf5',\n",
       " 'lstm.ipynb',\n",
       " 'weights-improvement-06-2.2085.hdf5',\n",
       " 'weights-improvement-02-2.6123.hdf5',\n",
       " 'Untitled.ipynb',\n",
       " 'international-airline-passengers.csv',\n",
       " 'weights-improvement-07-2.1350.hdf5',\n",
       " 'weights-improvement-03-2.4838.hdf5',\n",
       " 'weights-improvement-09-2.0056.hdf5',\n",
       " 'weights-improvement-11-1.8947.hdf5',\n",
       " 'weights-improvement-04-2.3810.hdf5',\n",
       " '.ipynb_checkpoints',\n",
       " 'alice_in_wonder.ipynb']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"weights-improvement-16-1.6494.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(filename)\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" rabbit-hole\n",
      "\n",
      "alice was beginning to get very tired of sitting by her sister on the\n",
      "bank, and of havi \"\n",
      "id an thi court of the sable, so she sele of the sable, bnd she saited to see if the sal off hnt lase and the house of the grurho of the sable, so she sell of the soeen on the court of the grure sfat saed to herself to ae io courte \n",
      "the mucen sole of the sable, and the suoedred a coeat hurry, and she tar down the white rabbit hoe to meke oot of the house, and she sar the fedd oitere an thi caak on a tiry ointles that she was not another hertenf to soeek of the crur, bnd she whrt har are toer a lotge of the goure caak tf the bourt of the sooe of the grore sh the brutte of the crurtes saale, and she suou lottle the queen sn think the house ou tererg the sabbit har and the bourt of the gour, and she srre thln she realed the hoose wotld bean so the boie, and saed to herself, 'i wesh the borro of the siisgnse thing!'\n",
      "\n",
      "'i don't know it ' said the magch hare.\n",
      "\n",
      "'aittring io the soeas toid ' said the manch hare.\n",
      "\n",
      "'ne course toenk,' said the manch hare.\n",
      "\n",
      "'ne course toenk,' said the manch hare.\n",
      "\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "start = np.random.randint(0, len(dataX)-1)\n",
    "pattern = dataX[start]\n",
    "print (\"Seed:\")\n",
    "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "\tx = np.reshape(pattern, (1, len(pattern), 1))\n",
    "\tx = x / float(n_vocab)\n",
    "\tprediction = model.predict(x, verbose=0)\n",
    "\tindex = np.argmax(prediction)\n",
    "\tresult = int_to_char[index]\n",
    "\tseq_in = [int_to_char[value] for value in pattern]\n",
    "\tsys.stdout.write(result)\n",
    "\tpattern.append(index)\n",
    "\tpattern = pattern[1:len(pattern)]\n",
    "print (\"\\nDone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
